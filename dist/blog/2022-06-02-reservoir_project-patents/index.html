<!DOCTYPE html><html lang="en-us"> <head><meta charset="UTF-8"><meta name="author" content="Garrett Honke"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="http://gmpg.org/xfn/11" rel="profile"><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Astro v5.15.9"><title>Reservoir  Patents &middot; garrett honke</title><meta name="description" content="computational neuroscientist"><!-- Scripts --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><!-- CSS --><link rel="stylesheet" href="/css/poole.css"><link rel="stylesheet" href="/css/syntax.css"><link rel="stylesheet" href="/css/hyde.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"></head> <body> <div class="sidebar"> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1> <a href="/">
garrett honke
</a> </h1> <p class="lead">computational neuroscientist</p> </div> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="/">about</a> <a class="sidebar-nav-item" href="/blog">blog</a> <a class="sidebar-nav-item" href="/cv">cv</a> <a href="http://www.twitter.com/garretthonke" class="fa fa-twitter"></a> <a href="https://github.com/ghonk"><i class="fa fa-github" aria-hidden="true"></i></a> <a href="https://scholar.google.com/citations?user=WPewiKcAAAAJ&hl=en" class="fa fa-graduation-cap"></a> <a href="https://stackexchange.com/users/4275635/ghonke?tab=accounts"><i class="fa fa-stack-overflow" aria-hidden="true"></i></a> <a href="https://www.linkedin.com/in/garretthonke"><i class="fa fa-linkedin" aria-hidden="true"></i></a> </nav> </div> </div> <div class="content container">  <div class="post"> <h1 class="post-title">Reservoir  Patents</h1> <span class="post-date">summer 2022</span> <p>This project investigated the effectiveness of using the connectivity structure of real biological connectomes (e.g., Drosophila) as interchangeable reservoir layers in SoTA neural architectures like UNets, LSTMs, and Transformers.</p>
<p><em>Ensemble machine learning with reservoir neural networks</em></p>
<p><a href="https://scholar.google.com/citations?view_op=view_citation&#x26;hl=en&#x26;user=WPewiKcAAAAJ&#x26;sortby=pubdate&#x26;citation_for_view=WPewiKcAAAAJ:vRqMK49ujn8C">Here</a></p>
<p><em>Attention-based brain emulation neural networks</em></p>
<p><a href="https://scholar.google.com/citations?view_op=view_citation&#x26;hl=en&#x26;user=WPewiKcAAAAJ&#x26;sortby=pubdate&#x26;citation_for_view=WPewiKcAAAAJ:l7t_Zn2s7bgC">Here</a></p> </div>  </div> </body></html>